{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":193567451,"sourceType":"kernelVersion"},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3900,"modelId":1902},{"sourceId":85994,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":72253,"modelId":76277}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset, Dataset, concatenate_datasets","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:11.861138Z","iopub.execute_input":"2024-08-25T17:31:11.861449Z","iopub.status.idle":"2024-08-25T17:31:14.627223Z","shell.execute_reply.started":"2024-08-25T17:31:11.861415Z","shell.execute_reply":"2024-08-25T17:31:14.626358Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_essays = load_dataset('csv', data_files = '/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\ntest_essays = load_dataset('csv', data_files = '/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntrain_prompts = load_dataset('csv', data_files = '/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:14.628714Z","iopub.execute_input":"2024-08-25T17:31:14.629163Z","iopub.status.idle":"2024-08-25T17:31:15.896063Z","shell.execute_reply.started":"2024-08-25T17:31:14.629130Z","shell.execute_reply":"2024-08-25T17:31:15.895202Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ace4c8fd3984ab191bf8f3625e14a03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df03bafb74d40daa8089e6306f8252f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd5ea818f7a54d5b868becad28043e4f"}},"metadata":{}}]},{"cell_type":"code","source":"train_essays, test_essays, train_prompts","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:15.897268Z","iopub.execute_input":"2024-08-25T17:31:15.897736Z","iopub.status.idle":"2024-08-25T17:31:15.904372Z","shell.execute_reply.started":"2024-08-25T17:31:15.897675Z","shell.execute_reply":"2024-08-25T17:31:15.903524Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(DatasetDict({\n     train: Dataset({\n         features: ['id', 'prompt_id', 'text', 'generated'],\n         num_rows: 1378\n     })\n }),\n DatasetDict({\n     train: Dataset({\n         features: ['id', 'prompt_id', 'text'],\n         num_rows: 3\n     })\n }),\n DatasetDict({\n     train: Dataset({\n         features: ['prompt_id', 'prompt_name', 'instructions', 'source_text'],\n         num_rows: 2\n     })\n }))"},"metadata":{}}]},{"cell_type":"code","source":"train_test_split = train_essays['train'].train_test_split(test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:15.906517Z","iopub.execute_input":"2024-08-25T17:31:15.906828Z","iopub.status.idle":"2024-08-25T17:31:15.930334Z","shell.execute_reply.started":"2024-08-25T17:31:15.906797Z","shell.execute_reply":"2024-08-25T17:31:15.929511Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = train_test_split['train'].rename_column('generated' , 'label')\nval = train_test_split['test'].rename_column('generated' , 'label')\ntest = test_essays['train']","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:15.931509Z","iopub.execute_input":"2024-08-25T17:31:15.931834Z","iopub.status.idle":"2024-08-25T17:31:15.940678Z","shell.execute_reply.started":"2024-08-25T17:31:15.931801Z","shell.execute_reply":"2024-08-25T17:31:15.939848Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train , val, test","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:15.941803Z","iopub.execute_input":"2024-08-25T17:31:15.942093Z","iopub.status.idle":"2024-08-25T17:31:15.953365Z","shell.execute_reply.started":"2024-08-25T17:31:15.942063Z","shell.execute_reply":"2024-08-25T17:31:15.952495Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['id', 'prompt_id', 'text', 'label'],\n     num_rows: 1102\n }),\n Dataset({\n     features: ['id', 'prompt_id', 'text', 'label'],\n     num_rows: 276\n }),\n Dataset({\n     features: ['id', 'prompt_id', 'text'],\n     num_rows: 3\n }))"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\n\nmodel_ckpt = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\n\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_use_double_quant = True,\n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_compute_dtype = torch.bfloat16\n)\n\ndef get_new_model():\n    return AutoModelForCausalLM.from_pretrained(model_ckpt, quantization_config = bnb_config, low_cpu_mem_usage = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:15.954593Z","iopub.execute_input":"2024-08-25T17:31:15.955217Z","iopub.status.idle":"2024-08-25T17:31:31.265956Z","shell.execute_reply.started":"2024-08-25T17:31:15.955173Z","shell.execute_reply":"2024-08-25T17:31:31.264523Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"prompts = ['<prompt> ' + ' '.join(text.split()[:-7]) for text in train_prompts['train']['instructions']]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:31.267168Z","iopub.execute_input":"2024-08-25T17:31:31.267477Z","iopub.status.idle":"2024-08-25T17:31:31.275149Z","shell.execute_reply.started":"2024-08-25T17:31:31.267438Z","shell.execute_reply":"2024-08-25T17:31:31.274234Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"texts = [' '.join(text.split()[:10]) for text in train['text']]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:31.276449Z","iopub.execute_input":"2024-08-25T17:31:31.276830Z","iopub.status.idle":"2024-08-25T17:31:31.350508Z","shell.execute_reply.started":"2024-08-25T17:31:31.276788Z","shell.execute_reply":"2024-08-25T17:31:31.349722Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def make_prompts(prompts, train_data):\n    return  [prompts[prompt_id] + ' <response> ' + text  for prompt_id, text in zip(train_data['prompt_id'], texts)]\n      \n    \ninput_texts = Dataset.from_dict({'text' : make_prompts(prompts, train)})","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:31.354786Z","iopub.execute_input":"2024-08-25T17:31:31.355086Z","iopub.status.idle":"2024-08-25T17:31:31.376322Z","shell.execute_reply.started":"2024-08-25T17:31:31.355054Z","shell.execute_reply":"2024-08-25T17:31:31.375505Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'left'\n\ndef preprocess(batch):\n    return tokenizer(batch['text'], padding = 'max_length', truncation = True, return_tensors = 'pt', max_length = 128) \n\ninputs = input_texts.map(preprocess, batched = True, batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:31.377588Z","iopub.execute_input":"2024-08-25T17:31:31.377882Z","iopub.status.idle":"2024-08-25T17:31:31.931418Z","shell.execute_reply.started":"2024-08-25T17:31:31.377851Z","shell.execute_reply":"2024-08-25T17:31:31.930399Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e68be7d020344d16be090e5cddcd8266"}},"metadata":{}}]},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:31.932602Z","iopub.execute_input":"2024-08-25T17:31:31.932930Z","iopub.status.idle":"2024-08-25T17:31:32.065736Z","shell.execute_reply.started":"2024-08-25T17:31:31.932896Z","shell.execute_reply":"2024-08-25T17:31:32.064659Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = get_new_model()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:31:32.066821Z","iopub.execute_input":"2024-08-25T17:31:32.067165Z","iopub.status.idle":"2024-08-25T17:32:49.257531Z","shell.execute_reply.started":"2024-08-25T17:31:32.067132Z","shell.execute_reply":"2024-08-25T17:32:49.256742Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e801095212884654a2b2d9e9aeb155dc"}},"metadata":{}}]},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:32:49.258721Z","iopub.execute_input":"2024-08-25T17:32:49.259279Z","iopub.status.idle":"2024-08-25T17:32:49.423513Z","shell.execute_reply.started":"2024-08-25T17:32:49.259236Z","shell.execute_reply":"2024-08-25T17:32:49.422307Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"%%time\n\ngenerated_texts = []\nbatch_size = 32\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfor i in range(0, len(inputs), batch_size):\n    start = i; end = min(i + batch_size, len(inputs))\n    batch = inputs[start:end]\n    \n    input_ids =  torch.tensor(batch['input_ids']).to(device)\n    attention_mask =  torch.tensor(batch['attention_mask']).to(device)\n     \n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            max_new_tokens = 1000,\n            top_p = 0.9,\n            top_k = 50,\n            temperature = 0.7,\n            repetition_penalty = 1.2,\n            do_sample = True\n        )\n    generated_texts.extend([tokenizer.decode(output, skip_sepcial_tokens = True) for output in outputs])\n    \n    print(f'batch {i // batch_size + 1} generation completed')\n    break","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:32:49.424906Z","iopub.execute_input":"2024-08-25T17:32:49.425252Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"cleaned_texts = [text.replace(tokenizer.pad_token, '').split('<response>')[1].strip() for text in generated_texts]\n\ncleaned_texts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lens = [len(text.split()) for text in cleaned_texts]\n\nlens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_data = Dataset.from_dict({'text' : cleaned_texts, 'label' : [1 for _ in range(len(cleaned_texts))]})\ntrain_ = train.remove_columns(['id','prompt_id'])\ntrain_data = concatenate_datasets([train_, gen_data])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(train_data).to_csv('train_data.csv', index = False)\n# train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_data = Dataset.from_pandas(pd.read_csv('/kaggle/working/train_data.csv'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast,\nimport torch\n\ngemma_model_ckpt = '/kaggle/input/gemma-2/transformers/gemma-2-2b/1'\ngemma_tokenizer = GemmaTokenizerFast.from_pretrained(gemma_model_ckpt)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_use_double_quant = True,\n    bnb_4bit_quant_type = 'nf4',\n    bnb_4bit_compute_dtype = torch.bfloat16\n)\n\ndef get_classifier():\n    return Gemma2ForSequenceClassification.from_pretrained(gemma_model_ckpt, num_labels = 2, quantization_config = bnb_config, low_cpu_mem_usage = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_data(batch):\n    return gemma_tokenizer(batch['text'], padding = True, truncation = True, max_length = 512)\n\ntrain_ds = train_data.map(tokenize_data, batched = True)\nval_ds = val.map(tokenize_data, batched = True)\ntest_ds = test.map(tokenize_data, batched = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds, test_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds)\n    return {'f1' : f1}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"per_device_bs =  2\noutput_dir = '/kaggle/working/gemma2'\n\nargs = TrainingArguments(\n    output_dir = output_dir,\n    num_train_epochs = 5,\n    learning_rate = 1e-5,\n    per_device_train_batch_size = per_device_bs,\n    per_device_eval_batch_size = per_device_bs,\n    eval_strategy = 'epoch',\n    save_strategy = 'epoch',\n    logging_steps = 100,\n    load_best_model_at_end = True,\n    overwrite_output_dir = True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = get_classifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model = classifier,\n    args = args,\n    train_dataset = train_ds,\n    eval_dataset = val_ds,\n    compute_metrics = compute_metrics,\n    tokenizer = bert_tokenizer\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = trainer.predict(test_ds)\n\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.sigmoid(torch.tensor(preds.predictions))\n\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nsub = pd.DataFrame({\n    'id' : test_['train']['id'],\n    'generated' : x[:, 0]\n})\n\nsub.to_csv('submission.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}